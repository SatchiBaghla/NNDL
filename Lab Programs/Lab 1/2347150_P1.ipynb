{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAB EXERCISE 1<br>\n",
    "You have been tasked with building simple neural networks to simulate the behavior of logic gates using a Single Layer Perceptron. This task will involve constructing, training, and testing perceptrons for the following gates: AND, OR, AND-NOT and XOR.\n",
    "1. AND Gate Classification<br>\n",
    "• Scenario:<br>\n",
    "You are tasked with building a simple neural network to simulate an AND gate using a Single Layer Perceptron. The AND gate outputs 1 only if both inputs are 1; otherwise, it outputs 0.<br>\n",
    "• Lab Task: Implement a Single Layer Perceptron using Python in Google Colab to classify the output of an AND gate given two binary inputs (0 or 1).<br>\n",
    "Follow these steps:<br>\n",
    "• Create a dataset representing the truth table of the AND gate.<br>\n",
    "• Define the perceptron model with one neuron, including the activation function and weights initialization(Try both random weights and defined weights).<br>\n",
    "• Train the perceptron using a suitable learning algorithm (e.g., gradient descent).<br>\n",
    "• Test the model with all possible input combinations and display the results.<br>\n",
    "Questions:<br>\n",
    "• How do the weights and bias values change during training for the AND gate?<br>\n",
    "• Can the perceptron successfully learn the AND logic with a linear decision boundary?<br>\n",
    "<br>\n",
    "2. OR Gate Classification<br>\n",
    "• Scenario:<br>\n",
    "Your next task is to design a perceptron that mimics the behavior of an OR gate. The OR gate outputs 1 if at least one of its inputs is 1.<br>\n",
    "• Lab Task: Using Google Colab, create a Single Layer Perceptron to classify the output of an OR gate.<br> \n",
    "Perform the following steps:<br>\n",
    "• Prepare the dataset for the OR gate's truth table.<br>\n",
    "• Define and initialize a Single Layer Perceptron model.<br>\n",
    "• Implement the training process and adjust the perceptron's weights.<br>\n",
    "• Validate the perceptron's performance with the OR gate input combinations.<br>\n",
    "Questions:<br>\n",
    "• What changes in the perceptron's weights are necessary to represent the OR gate logic?<br>\n",
    "• How does the linear decision boundary look for the OR gate classification?<br>\n",
    "<br>\n",
    "3. AND-NOT Gate Classification<br>\n",
    "• Scenario:<br>\n",
    "You need to implement an AND-NOT gate, which outputs 1 only if the first input is 1 and the second input is 0.<br>\n",
    "• Lab Task: Design a Single Layer Perceptron in Google Colab to classify the output of an AND-NOT gate.<br> \n",
    "Follow these steps:<br>\n",
    "• Create the truth table for the AND-NOT gate.<br>\n",
    "• Define a perceptron model with an appropriate activation function.<br>\n",
    "• Train the model on the AND-NOT gate dataset.<br>\n",
    "• Test the model and analyze its classification accuracy.<br>\n",
    "Questions:<br>\n",
    "• What is the perceptron's weight configuration after training for the AND-NOT gate?<br>\n",
    "• How does the perceptron handle cases where both inputs are 1 or 0?<br>\n",
    "<br>\n",
    "4. XOR Gate Classification<br>\n",
    "• Scenario:<br>\n",
    "The XOR gate is known for its complexity, as it outputs 1 only when the inputs are different. This is a challenge for a Single Layer Perceptron since XOR is not linearly separable.<br>\n",
    "• Lab Task: Attempt to implement a Single Layer Perceptron in Google Colab to classify the output of an XOR gate.<br> \n",
    "Perform the following steps:<br>\n",
    "• Create the XOR gate's truth table dataset.<br>\n",
    "• Implement the perceptron model and train it using the XOR dataset.<br>\n",
    "• Observe and discuss the perceptron's performance in this scenario.<br>\n",
    "Questions:<br>\n",
    "• Why does the Single Layer Perceptron struggle to classify the XOR gate?<br>\n",
    "• What modifications can be made to the neural network model to handle the XOR gate correctly?<br>\n",
    "<br>\n",
    "Instructions for Lab Work in Google Colab:Setup: Import necessary libraries (e.g., NumPy) and create datasets for each logic gate.<br>\n",
    "Model Implementation: Write the code for the Single Layer Perceptron, including forward and backward passes.<br>\n",
    "Training: Use a learning algorithm to adjust weights and biases.<br>\n",
    "Evaluation: Test the perceptron's performance for each logic gate and plot the decision boundaries where applicable.<br>\n",
    "Analysis: Document the results and answer the provided questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AND GATE CLASSIFICATION\n",
    "\n",
    "| Input 1 | Input 2 | Output |\n",
    "|---------|---------|--------|\n",
    "|    0    |    0    |    0   |\n",
    "|    0    |    1    |    0   |\n",
    "|    1    |    0    |    0   |\n",
    "|    1    |    1    |    1   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# AND gate truth table\n",
    "X_and = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Inputs\n",
    "y_and = np.array([0, 0, 0, 1])  # Output (AND logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for perceptron\n",
    "# Step 1: Define the activation function (Heaviside Step function)\n",
    "def activation_function(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "# Step 2: Define the perceptron model\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.1):\n",
    "        # Initialize weights randomly (You can also set custom weights for demonstration)\n",
    "        self.weights = np.random.rand(2)  # Two weights for two inputs\n",
    "        self.bias = np.random.rand()      # Bias term\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    # Step 3: Perceptron prediction (forward pass)\n",
    "    def predict(self, inputs):\n",
    "        # Calculate the weighted sum of inputs + bias\n",
    "        weighted_sum = np.dot(inputs, self.weights) + self.bias\n",
    "        # Apply the activation function\n",
    "        return activation_function(weighted_sum)\n",
    "\n",
    "    # Step 4: Train the perceptron using the training data\n",
    "    def train(self, training_inputs, labels, epochs=20):\n",
    "        for epoch in range(epochs):\n",
    "            print(f'Epoch {epoch+1}/{epochs}:')\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                # Make a prediction\n",
    "                prediction = self.predict(inputs)\n",
    "                # Calculate the error (difference between predicted and actual label)\n",
    "                error = label - prediction\n",
    "                # Update the weights and bias using the perceptron learning rule\n",
    "                self.weights += self.learning_rate * error * inputs\n",
    "                self.bias += self.learning_rate * error\n",
    "                print(f' Inputs: {inputs}, Prediction: {prediction}, Actual: {label}, Error: {error}')\n",
    "                print(f' Updated Weights: {self.weights}, Updated Bias: {self.bias}')\n",
    "            print()\n",
    "\n",
    "# Step 6: Initialize the perceptron model\n",
    "perceptron = Perceptron(learning_rate=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.38419313 0.42441188], Updated Bias: 0.8022491958132121\n",
      " Inputs: [0 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.38419313 0.32441188], Updated Bias: 0.7022491958132121\n",
      " Inputs: [1 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.28419313 0.32441188], Updated Bias: 0.6022491958132121\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.28419313 0.32441188], Updated Bias: 0.6022491958132121\n",
      "\n",
      "Epoch 2/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.28419313 0.32441188], Updated Bias: 0.5022491958132121\n",
      " Inputs: [0 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.28419313 0.22441188], Updated Bias: 0.40224919581321217\n",
      " Inputs: [1 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.18419313 0.22441188], Updated Bias: 0.3022491958132122\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.22441188], Updated Bias: 0.3022491958132122\n",
      "\n",
      "Epoch 3/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.18419313 0.22441188], Updated Bias: 0.20224919581321218\n",
      " Inputs: [0 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: 0.10224919581321218\n",
      " Inputs: [1 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.08419313 0.12441188], Updated Bias: 0.0022491958132121737\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.08419313 0.12441188], Updated Bias: 0.0022491958132121737\n",
      "\n",
      "Epoch 4/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.08419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.08419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.08419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 1], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 5/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      "\n",
      "Epoch 6/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      "\n",
      "Epoch 7/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      "\n",
      "Epoch 8/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      "\n",
      "Epoch 9/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      "\n",
      "Epoch 10/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      "\n",
      "Testing the model:\n",
      " Inputs: [0 0], Predicted Output: 0\n",
      " Inputs: [0 1], Predicted Output: 0\n",
      " Inputs: [1 0], Predicted Output: 0\n",
      " Inputs: [1 1], Predicted Output: 1\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Train the perceptron model\n",
    "perceptron.train(X_and, y_and, epochs=10)\n",
    "\n",
    "# Step 8: Test the perceptron model\n",
    "print('Testing the model:')\n",
    "for inputs in X_and:\n",
    "    output = perceptron.predict(inputs)\n",
    "    print(f' Inputs: {inputs}, Predicted Output: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight and Bias Changes: The weights and bias are adjusted based on the error between the predicted and actual outputs during each training iteration.<br>\n",
    "Linear Decision Boundary: Yes, the perceptron can successfully learn the AND gate logic as it is linearly separable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR GATE CLASSIFICATION\n",
    "\n",
    "| Input 1 | Input 2 | Output |\n",
    "|---------|---------|--------|\n",
    "|    0    |    0    |    0   |\n",
    "|    0    |    1    |    1   |\n",
    "|    1    |    0    |    1   |\n",
    "|    1    |    1    |    1   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR gate truth table\n",
    "X_or = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_or = np.array([0, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [0 1], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 2/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 3/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 4/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 5/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 6/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 7/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 8/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 9/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 10/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Testing the model:\n",
      " Inputs: [0 0], Predicted Output: 0\n",
      " Inputs: [0 1], Predicted Output: 1\n",
      " Inputs: [1 0], Predicted Output: 1\n",
      " Inputs: [1 1], Predicted Output: 1\n"
     ]
    }
   ],
   "source": [
    "perceptron.train(X_or, y_or, epochs=10)\n",
    "\n",
    "print('Testing the model:')\n",
    "for inputs in X_or:\n",
    "    output = perceptron.predict(inputs)\n",
    "    print(f' Inputs: {inputs}, Predicted Output: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight Changes: The weights will adjust to represent the OR logic, which requires a different decision boundary from AND.<br>\n",
    "Linear Decision Boundary: The OR logic can be learned with a linear decision boundary because it's also linearly separable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AND-NOT CLASSIFICATION\n",
    "\n",
    "| Input 1 | Input 2 | Output |\n",
    "|---------|---------|--------|\n",
    "|    0    |    0    |    0   |\n",
    "|    0    |    1    |    0   |\n",
    "|    1    |    0    |    1   |\n",
    "|    1    |    1    |    0   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_andnot = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_andnot = np.array([0, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [0.18419313 0.12441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [0.18419313 0.02441188], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 0], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [0.28419313 0.02441188], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [ 0.18419313 -0.07558812], Updated Bias: -0.19775080418678784\n",
      "\n",
      "Epoch 2/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.18419313 -0.07558812], Updated Bias: -0.19775080418678784\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.18419313 -0.07558812], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 0], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [ 0.28419313 -0.07558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [ 0.18419313 -0.17558812], Updated Bias: -0.19775080418678784\n",
      "\n",
      "Epoch 3/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.18419313 -0.17558812], Updated Bias: -0.19775080418678784\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.18419313 -0.17558812], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 0], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [ 0.28419313 -0.17558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [ 0.18419313 -0.27558812], Updated Bias: -0.19775080418678784\n",
      "\n",
      "Epoch 4/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.18419313 -0.27558812], Updated Bias: -0.19775080418678784\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.18419313 -0.27558812], Updated Bias: -0.19775080418678784\n",
      " Inputs: [1 0], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 5/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 6/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 7/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 8/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 9/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 10/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [1 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Testing the model:\n",
      " Inputs: [0 0], Predicted Output: 0\n",
      " Inputs: [0 1], Predicted Output: 0\n",
      " Inputs: [1 0], Predicted Output: 1\n",
      " Inputs: [1 1], Predicted Output: 0\n"
     ]
    }
   ],
   "source": [
    "perceptron.train(X_andnot, y_andnot, epochs=10)\n",
    "\n",
    "print('Testing the model:')\n",
    "for inputs in X_andnot:\n",
    "    output = perceptron.predict(inputs)\n",
    "    print(f' Inputs: {inputs}, Predicted Output: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight Configuration: The weights will configure to output 1 only when the first input is 1 and the second is 0.<br>\n",
    "Handling Special Cases: The perceptron will output 0 when both inputs are 1 or both are 0, correctly classifying the AND-NOT logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XOR GATE CLASSIFICATION\n",
    "\n",
    "| Input 1 | Input 2 | Output |\n",
    "|---------|---------|--------|\n",
    "|    0    |    0    |    0   |\n",
    "|    0    |    1    |    1   |\n",
    "|    1    |    0    |    1   |\n",
    "|    1    |    1    |    0   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR gate truth table\n",
    "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_xor = np.array([0, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [ 0.28419313 -0.17558812], Updated Bias: 0.0022491958132121737\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.28419313 -0.17558812], Updated Bias: 0.0022491958132121737\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [ 0.18419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 2/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.18419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [ 0.18419313 -0.17558812], Updated Bias: 0.0022491958132121737\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.18419313 -0.17558812], Updated Bias: 0.0022491958132121737\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [ 0.08419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 3/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.08419313 -0.27558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [ 0.08419313 -0.17558812], Updated Bias: 0.0022491958132121737\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.08419313 -0.17558812], Updated Bias: 0.0022491958132121737\n",
      " Inputs: [1 1], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [ 0.08419313 -0.17558812], Updated Bias: 0.0022491958132121737\n",
      "\n",
      "Epoch 4/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [ 0.08419313 -0.17558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [ 0.08419313 -0.07558812], Updated Bias: 0.0022491958132121737\n",
      " Inputs: [1 0], Prediction: 1, Actual: 1, Error: 0\n",
      " Updated Weights: [ 0.08419313 -0.07558812], Updated Bias: 0.0022491958132121737\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [-0.01580687 -0.17558812], Updated Bias: -0.09775080418678783\n",
      "\n",
      "Epoch 5/10:\n",
      " Inputs: [0 0], Prediction: 0, Actual: 0, Error: 0\n",
      " Updated Weights: [-0.01580687 -0.17558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [-0.01580687 -0.07558812], Updated Bias: 0.0022491958132121737\n",
      " Inputs: [1 0], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [ 0.08419313 -0.07558812], Updated Bias: 0.10224919581321218\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [-0.01580687 -0.17558812], Updated Bias: 0.0022491958132121737\n",
      "\n",
      "Epoch 6/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [-0.01580687 -0.17558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [-0.01580687 -0.07558812], Updated Bias: 0.0022491958132121737\n",
      " Inputs: [1 0], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [ 0.08419313 -0.07558812], Updated Bias: 0.10224919581321218\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [-0.01580687 -0.17558812], Updated Bias: 0.0022491958132121737\n",
      "\n",
      "Epoch 7/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [-0.01580687 -0.17558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [-0.01580687 -0.07558812], Updated Bias: 0.0022491958132121737\n",
      " Inputs: [1 0], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [ 0.08419313 -0.07558812], Updated Bias: 0.10224919581321218\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [-0.01580687 -0.17558812], Updated Bias: 0.0022491958132121737\n",
      "\n",
      "Epoch 8/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [-0.01580687 -0.17558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [-0.01580687 -0.07558812], Updated Bias: 0.0022491958132121737\n",
      " Inputs: [1 0], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [ 0.08419313 -0.07558812], Updated Bias: 0.10224919581321218\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [-0.01580687 -0.17558812], Updated Bias: 0.0022491958132121737\n",
      "\n",
      "Epoch 9/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [-0.01580687 -0.17558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [-0.01580687 -0.07558812], Updated Bias: 0.0022491958132121737\n",
      " Inputs: [1 0], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [ 0.08419313 -0.07558812], Updated Bias: 0.10224919581321218\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [-0.01580687 -0.17558812], Updated Bias: 0.0022491958132121737\n",
      "\n",
      "Epoch 10/10:\n",
      " Inputs: [0 0], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [-0.01580687 -0.17558812], Updated Bias: -0.09775080418678783\n",
      " Inputs: [0 1], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [-0.01580687 -0.07558812], Updated Bias: 0.0022491958132121737\n",
      " Inputs: [1 0], Prediction: 0, Actual: 1, Error: 1\n",
      " Updated Weights: [ 0.08419313 -0.07558812], Updated Bias: 0.10224919581321218\n",
      " Inputs: [1 1], Prediction: 1, Actual: 0, Error: -1\n",
      " Updated Weights: [-0.01580687 -0.17558812], Updated Bias: 0.0022491958132121737\n",
      "\n",
      "Testing the model:\n",
      " Inputs: [0 0], Predicted Output: 1\n",
      " Inputs: [0 1], Predicted Output: 0\n",
      " Inputs: [1 0], Predicted Output: 0\n",
      " Inputs: [1 1], Predicted Output: 0\n"
     ]
    }
   ],
   "source": [
    "perceptron.train(X_xor, y_xor, epochs=10)\n",
    "\n",
    "print('Testing the model:')\n",
    "for inputs in X_xor:\n",
    "    output = perceptron.predict(inputs)\n",
    "    print(f' Inputs: {inputs}, Predicted Output: {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training: The XOR logic is not linearly separable, so a Single Layer Perceptron will struggle to learn it.<br>\n",
    "Struggle with XOR: The XOR gate requires a non-linear decision boundary, which a Single Layer Perceptron cannot represent due to its linear nature.<br>\n",
    "Modifications for XOR: To handle XOR, you would need a Multi-Layer Perceptron (MLP) with at least one hidden layer, enabling the model to capture non-linear patterns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
